{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4 Random Forest\n",
    "\n",
    "**What is the random forest?**\n",
    "\n",
    "Random Forest is an ensemble learning algorithm that constructs many decision trees during the training. It predicts the mode of the classes for classification tasks and the mean prediction of trees for regression tasks.\n",
    "\n",
    "Watch the 5m11s video below for a visual guide to random forests.\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/cIbj0WuK41w?si=W_3Z8_o6hwWJ2i_C\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>\n",
    "\n",
    "Source: [Visual Guide to Random Forests](https://www.youtube.com/watch?v=cIbj0WuK41w&ab_channel=Econoscent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advantages of decision trees**\n",
    "\n",
    "- Like decision trees, when employing random forests,  data preprocessing becomes easier. For example, there is no need for normalisation or dealing with missing values, as random forests handle missing values.\n",
    "- It can be used for both regression and classification tasks. \n",
    "- The random forest offers lots of parameters to tweak and improve your machine learning model.\n",
    "- The hyperparameters, used in random forests, often produce a good prediction result.\n",
    "- If there are enough trees in the forest, the classifier wonâ€™t overfit the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disadvantages of decision trees**\n",
    "\n",
    "- While the random forest is a good classification algorithm, it can be limited with regression especially when data has linear nature.\n",
    "- If your data has categorical variables with different levels of attributes this can be a big problem because the random forest algorithm will favor those with more values which can pose a prediction risk.\n",
    "- Although much lower risk than decision trees, overfitting is still a risk with random forests.\n",
    "- Parameter complexity (used for tuning and optimisation). "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
